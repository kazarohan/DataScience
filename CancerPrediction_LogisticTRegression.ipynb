{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPra7fI23soL3cv843e1W2W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazarohan/DataScience/blob/master/CancerPrediction_LogisticTRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Jv88sxbMyL"
      },
      "source": [
        "\n",
        "# performing linear algebra \n",
        "import numpy as np  \n",
        "  \n",
        "# data processing \n",
        "import pandas as pd \n",
        "  \n",
        "# visualisation \n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DxWqE_icaPp",
        "outputId": "ec18f1f1-7629-46c6-f41e-51131ea50200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "data = pd.read_csv(\"data.csv\") \n",
        "  \n",
        "print (data.head) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of            id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
            "0      842302         M  ...                  0.11890          NaN\n",
            "1      842517         M  ...                  0.08902          NaN\n",
            "2    84300903         M  ...                  0.08758          NaN\n",
            "3    84348301         M  ...                  0.17300          NaN\n",
            "4    84358402         M  ...                  0.07678          NaN\n",
            "..        ...       ...  ...                      ...          ...\n",
            "564    926424         M  ...                  0.07115          NaN\n",
            "565    926682         M  ...                  0.06637          NaN\n",
            "566    926954         M  ...                  0.07820          NaN\n",
            "567    927241         M  ...                  0.12400          NaN\n",
            "568     92751         B  ...                  0.07039          NaN\n",
            "\n",
            "[569 rows x 33 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huNTF0pAc7ng"
      },
      "source": [
        "data.drop(['Unnamed: 32', 'id'], axis = 1) \n",
        "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis] \n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnoVPoPBd1NA",
        "outputId": "c3363e89-3e3d-45d4-b778-a063928e04f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "data.head(n=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.1184</td>\n",
              "      <td>0.2776</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.1471</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.095</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.4</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0  842302          1  ...                   0.1189          NaN\n",
              "\n",
              "[1 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQTB3ZwieS-5"
      },
      "source": [
        "y = data.diagnosis.values \n",
        "x_data = data.drop(['diagnosis'], axis = 1) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zozqbvfneA1h"
      },
      "source": [
        "x = (x_data - np.min(x_data))/(np.max(x_data) - np.min(x_data)).values \n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT04vvbjefyp",
        "outputId": "85334ad5-0bd3-4e97-d015-c4acbec6375d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_test, y_train, y_test = train_test_split( \n",
        "\tx, y, test_size = 0.15, random_state = 42) \n",
        "\n",
        "x_train = x_train.T \n",
        "x_test = x_test.T \n",
        "y_train = y_train.T \n",
        "y_test = y_test.T \n",
        "\n",
        "print(\"x train: \", x_train.shape) \n",
        "print(\"x test: \", x_test.shape) \n",
        "print(\"y train: \", y_train.shape) \n",
        "print(\"y test: \", y_test.shape) \n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x train:  (32, 483)\n",
            "x test:  (32, 86)\n",
            "y train:  (483,)\n",
            "y test:  (86,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYZrM-1Uh5Q6"
      },
      "source": [
        "Code : Weight and bias\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94n8HrpjenUe"
      },
      "source": [
        "def initialize_weights_and_bias(dimension): \n",
        "    w = np.full((dimension, 1), 0.01) \n",
        "    b = 0.0\n",
        "    return w, b"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf5D2VTtiKFQ"
      },
      "source": [
        "Code : Sigmoid Function â€“ calculating z value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpr3e7qWiMLD"
      },
      "source": [
        "# z = np.dot(w.T, x_train)+b \n",
        "def sigmoid(z): \n",
        "    y_head = 1/(1 + np.exp(-z)) \n",
        "    return y_head "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fes7Iw3iUxp"
      },
      "source": [
        "Code : Forward-Backward Propogation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIRZ-sZRiWCi"
      },
      "source": [
        "def forward_backward_propagation(w, b, x_train, y_train): \n",
        "\tz = np.dot(w.T, x_train) + b \n",
        "\ty_head = sigmoid(z) \n",
        "\tloss = - y_train * np.log(y_head) - (1 - y_train) * np.log(1 - y_head) \n",
        "\t# x_train.shape[1] is for scaling \n",
        "\tcost = (np.sum(loss)) / x_train.shape[1]\t \n",
        "\n",
        "\t# backward propagation \n",
        "\tderivative_weight = (np.dot(x_train, ( \n",
        "\t\t(y_head - y_train).T))) / x_train.shape[1] \n",
        "\tderivative_bias = np.sum( \n",
        "\t\ty_head-y_train) / x_train.shape[1]\t\t\t\t \n",
        "\tgradients = {\"derivative_weight\": derivative_weight, \n",
        "\t\t\t\t\"derivative_bias\": derivative_bias} \n",
        "\treturn cost, gradients "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff-wAQlKibyb"
      },
      "source": [
        "Code : Updating Parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yjkoV-_iZnA"
      },
      "source": [
        "def update(w, b, x_train, y_train, learning_rate, number_of_iterarion): \n",
        "    cost_list = [] \n",
        "    cost_list2 = [] \n",
        "    index = [] \n",
        "  \n",
        "    # updating(learning) parameters is number_of_iterarion times \n",
        "    for i in range(number_of_iterarion): \n",
        "        # make forward and backward propagation and find cost and gradients \n",
        "        cost, gradients = forward_backward_propagation(w, b, x_train, y_train) \n",
        "        cost_list.append(cost) \n",
        "  \n",
        "        # lets update \n",
        "        w = w - learning_rate * gradients[\"derivative_weight\"] \n",
        "        b = b - learning_rate * gradients[\"derivative_bias\"] \n",
        "        if i % 10 == 0: \n",
        "            cost_list2.append(cost) \n",
        "            index.append(i) \n",
        "            print (\"Cost after iteration % i: % f\" %(i, cost)) \n",
        "  \n",
        "    # update(learn) parameters weights and bias \n",
        "    parameters = {\"weight\": w, \"bias\": b} \n",
        "    plt.plot(index, cost_list2) \n",
        "    plt.xticks(index, rotation ='vertical') \n",
        "    plt.xlabel(\"Number of Iterarion\") \n",
        "    plt.ylabel(\"Cost\") \n",
        "    plt.show() \n",
        "    return parameters, gradients, cost_list \n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC6I0ITFiqbE"
      },
      "source": [
        "Code : Predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTQjEqbZishz"
      },
      "source": [
        "def predict(w, b, x_test): \n",
        "    # x_test is a input for forward propagation \n",
        "    z = sigmoid(np.dot(w.T, x_test)+b) \n",
        "    Y_prediction = np.zeros((1, x_test.shape[1])) \n",
        "  \n",
        "    # if z is bigger than 0.5, our prediction is sign one (y_head = 1), \n",
        "    # if z is smaller than 0.5, our prediction is sign zero (y_head = 0), \n",
        "    for i in range(z.shape[1]): \n",
        "        if z[0, i]<= 0.5: \n",
        "            Y_prediction[0, i] = 0\n",
        "        else: \n",
        "            Y_prediction[0, i] = 1\n",
        "  \n",
        "    return Y_prediction "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO0EgJq9izPr"
      },
      "source": [
        "Code : Logistic Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n-s4mHmi0QZ",
        "outputId": "8537cdd1-a449-4ee4-a075-34df4bc675f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "def logistic_regression(x_train, y_train, x_test, y_test,  \n",
        "                        learning_rate,  num_iterations): \n",
        "  \n",
        "    dimension = x_train.shape[0] \n",
        "    w, b = initialize_weights_and_bias(dimension) \n",
        "      \n",
        "    parameters, gradients, cost_list = update( \n",
        "        w, b, x_train, y_train, learning_rate, num_iterations) \n",
        "      \n",
        "    y_prediction_test = predict( \n",
        "        parameters[\"weight\"], parameters[\"bias\"], x_test) \n",
        "    y_prediction_train = predict( \n",
        "        parameters[\"weight\"], parameters[\"bias\"], x_train) \n",
        "  \n",
        "    # train / test Errors \n",
        "    print(\"train accuracy: {} %\".format( \n",
        "        100 - np.mean(np.abs(y_prediction_train - y_train)) * 100)) \n",
        "    print(\"test accuracy: {} %\".format( \n",
        "        100 - np.mean(np.abs(y_prediction_test - y_test)) * 100)) \n",
        "      \n",
        "logistic_regression(x_train, y_train, x_test,  \n",
        "                    y_test, learning_rate = 1, num_iterations = 100)  \n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration  0:  nan\n",
            "Cost after iteration  10:  nan\n",
            "Cost after iteration  20:  nan\n",
            "Cost after iteration  30:  nan\n",
            "Cost after iteration  40:  nan\n",
            "Cost after iteration  50:  nan\n",
            "Cost after iteration  60:  nan\n",
            "Cost after iteration  70:  nan\n",
            "Cost after iteration  80:  nan\n",
            "Cost after iteration  90:  nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train accuracy: 37.267080745341616 %\n",
            "test accuracy: 37.2093023255814 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZl18pK7jAVK"
      },
      "source": [
        "from sklearn import linear_model \n",
        "logreg = linear_model.LogisticRegression(random_state = 42, max_iter = 150) \n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acTKiKoHlZhj",
        "outputId": "35a57186-baf7-4f4f-84f2-82dcbbc23475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "S = logreg.fit(x_train.T, y_train.T)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-20955d4e92d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdZtVZbDlHH0",
        "outputId": "188e4c33-d1be-4b7c-ef79-37ae8909529a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# print(\"test accuracy: {} \".format( \n",
        "#     logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T))) \n",
        "print(\"train accuracy: {} \".format( \n",
        "    logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T))) "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4d067f540760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     logreg.fit(x_train.T, y_train.T).score(x_test.T, y_test.T)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m print(\"train accuracy: {} \".format( \n\u001b[0;32m----> 4\u001b[0;31m     logreg.fit(x_train.T, y_train.T).score(x_train.T, y_train.T))) \n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    }
  ]
}